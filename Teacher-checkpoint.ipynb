{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Cleaning - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"feedback.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5000 non-null   object\n",
      " 1   label   5000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's been about 14 years since Sharon Stone aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone needed to make a car payment... this i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Guidelines state that a comment must conta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a muddled mish-mash of clichés f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before Stan Laurel became the smaller half of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  It's been about 14 years since Sharon Stone aw...      0\n",
       "1  someone needed to make a car payment... this i...      0\n",
       "2  The Guidelines state that a comment must conta...      0\n",
       "3  This movie is a muddled mish-mash of clichés f...      0\n",
       "4  Before Stan Laurel became the smaller half of ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['label'] = df['Text Label'].map({'Non-Bullying': 0, 'Bullying': 1})\n",
    "df['message'] = df['text']\n",
    "#df.drop(['Text Label','Tweet'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=\"label\", data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-583a998d3dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ''\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df.message:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10).generate(comment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (12, 12), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Formal DAta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X) # Fit the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticR = LogisticRegression()\n",
    "LogisticR.fit(X_train, y_train) \n",
    "y_pred = LogisticR.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "LR = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForest = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "RandomForest.fit(X_train, y_train) \n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "RF = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "AdaBoost = DecisionTreeClassifier()\n",
    "AdaBoost.fit(X_train, y_train)\n",
    "y_pred = AdaBoost.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "AB= accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MultinomialNB = MultinomialNB()\n",
    "MultinomialNB.fit(X_train, y_train)\n",
    "y_pred = MultinomialNB.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "MNB = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "svm = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAT Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "cat = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = RandomForestClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(ensemble)\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "E= accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = df.label.nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "\n",
    "    text = re.sub(r'http\\S+', \" \", text)    # remove urls\n",
    "    text = re.sub(r'@\\w+',' ',text)         # remove mentions\n",
    "    text = re.sub(r'#\\w+', ' ', text)       # remove hastags\n",
    "    text = re.sub('r<.*?>',' ', text)       # remove html tags\n",
    "    \n",
    "    # remove stopwords \n",
    "    text = text.split()\n",
    "    text = \" \".join([word for word in text if not word in stop_words])\n",
    "\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: cleaning_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length\n",
    "max_len_words = max(list(df['text'].apply(len)))\n",
    "print(max_len_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x_train, y_train, max_len_word):\n",
    "    # because the data distribution is imbalanced, \"stratify\" is used\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, \n",
    "                                                      test_size=.2, shuffle=True, \n",
    "                                                      stratify=y_train, random_state=0)\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    sequence_dict = tokenizer.word_index\n",
    "    word_dict = dict((num, val) for (val, num) in sequence_dict.items())\n",
    "\n",
    "    # Sequence data\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    train_padded = pad_sequences(train_sequences,\n",
    "                                 maxlen=max_len_word,\n",
    "                                 truncating='post',\n",
    "                                 padding='post')\n",
    "    \n",
    "    val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "    val_padded = pad_sequences(val_sequences,\n",
    "                                maxlen=max_len_word,\n",
    "                                truncating='post',\n",
    "                                padding='post', )\n",
    "    \n",
    "    print(train_padded.shape)\n",
    "    print(val_padded.shape)\n",
    "    print('Total words: {}'.format(len(word_dict)))\n",
    "    return train_padded, val_padded, y_train, y_val, word_dict\n",
    "\n",
    "X_train, X_val, y_train, y_val, word_dict = tokenizer(df.text, df.label, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = Sequential([\n",
    "    layers.Embedding(5000, 100, input_length=100),\n",
    "    layers.SimpleRNN(64, return_sequences=True, recurrent_dropout=0.4),\n",
    "    layers.GlobalAveragePooling1D(),    # or layers.Flatten()\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = model.fit(X_train, y_train,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = trained.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['accuracy'])\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "def build_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(5000, 100, input_length=100))\n",
    "\n",
    "\n",
    "    model.add(Conv1D(64, 2, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    #model.add(MaxPooling1D(2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=1024,activation=\"relu\"))\n",
    "    model.add(Dense(units=512,activation=\"relu\"))\n",
    "    \n",
    "    model.add(Dense(units=num_classes,activation=\"softmax\"))\n",
    "    \n",
    "    optimizer = Adam(lr=0.000055,beta_1=0.9,beta_2=0.999)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,metrics=[\"accuracy\"],loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = cnn_model.fit(X_train, y_train,\n",
    "                    epochs=10, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = cnn_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_history.history['accuracy'])\n",
    "plt.plot(cnn_history.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.plot(cnn_history.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing libraries for model evaluation and algorithms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#dl libraraies\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization,Reshape,Dot,Concatenate,Add,Lambda\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "#import cv2\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# specifically for deeplearning.\n",
    "from tensorflow.keras.layers import Dropout, Flatten,Activation,Input,Embedding\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataframe\n",
    "df=pd.read_csv('feedback.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters which will be used throughout\n",
    "num_words = 15000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "val_size = 1000  # Size of the validation set\n",
    "epochs = 20  # Number of epochs we usually start to train with\n",
    "batch_size = 512  # Size of the batches used in the mini-batch gradient descent\n",
    "#Taking only two columns since it's a sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets conssits of every document as an array of tokenized words which are later appended to docs \n",
    "tweets=[word_tokenize(tweet) for tweet in df['text']]\n",
    "docs=[]\n",
    "for j in range(0,len(tweets)):\n",
    "    docs.append(tweets[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stops included both the stopwords and punctuations\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "not_list = [\"n't\", \"not\", \"no\"]\n",
    "stops.update(punctuations)\n",
    "stops.update(not_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the simple pos(part of speech) tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the pos tag for a word\n",
    "from nltk import pos_tag\n",
    "# now we are going to clean our data \n",
    "# we will remove stopwords and punctuations and lemmatize each document\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def clean(words):\n",
    "    output=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stops or word.lower() in not_list:\n",
    "            pos=pos_tag(word)\n",
    "            clean_word=lemmatizer.lemmatize(word,pos=get_simple_pos(pos[0][1]))\n",
    "            output.append(clean_word.lower())\n",
    "    str1=\" \".join(output).encode('utf-8')        \n",
    "    return str1\n",
    "#docs=[ clean(doc) for doc in docs]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['text','label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking variables to be used for train test split as X,y\n",
    "X,Y=df['text'].values,pd.get_dummies(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tokenizers to create the tokens having no of words=15000(num_words)\n",
    "tk = Tokenizer(num_words=num_words,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "#Complete data is tokenized to vectors and padding is done using zeros to match its length to the largest text in the dataset.\n",
    "tk.fit_on_texts(X)\n",
    "X = tk.texts_to_sequences(X)\n",
    "X = pad_sequences(X)\n",
    "#print(X[:2])\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tk,open('transform2.pkl','wb'))\n",
    "#files.download('transform2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
    "print('# Train data samples:', X_train.shape)\n",
    "print('# Test data samples:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function defined to test the models in the test set\n",
    "def test_model(model, epoch_stop):\n",
    "    model.fit(X_test\n",
    "              , Y_test\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=batch_size\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128 #dimension of the word embedding vector for each word in a sequence \n",
    "lstm_out = 196  #no of lstm layers\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
    "#Adding dropout\n",
    "lstm_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "#Adding a regularized dense layer\n",
    "lstm_model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "lstm_model.add(layers.Dropout(0.5))\n",
    "lstm_model.add(Dense(2,activation='softmax'))\n",
    "lstm_model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
    "trained=lstm_model.fit(X_train, Y_train, epochs = 50, batch_size=batch_size,validation_data=(X_test, Y_test),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction by our lstm model on the test dataset\n",
    "lstm_results = test_model(lstm_model, 3)\n",
    "print('/n')\n",
    "print('Test accuracy of lstm model: {0:.2f}%'.format(lstm_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = (lstm_results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['accuracy'])\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "EMBEDDING_DIM = 50\n",
    "N_CLASSES = 2\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "\n",
    "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(num_words, embed_dim,input_length = X_train.shape[1],trainable=True)\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "average = GlobalAveragePooling1D()(embedded_sequences)\n",
    "predictions = Dense(2, activation='softmax')(average)\n",
    "\n",
    "model = Model(sequence_input, predictions)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size,validation_data=(X_test, Y_test),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = trained.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['accuracy'])\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
    "from keras.layers import LSTM,Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "filepath=\"weights_best_cnn.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = model.fit(X_train, Y_train, epochs = 5, batch_size=batch_size,validation_data=(X_test, Y_test),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyd = trained.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['accuracy'])\n",
    "plt.plot(trained.history['val_accuracy'])\n",
    "plt.title('Accuracy Curves')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trained.history['loss'])\n",
    "plt.plot(trained.history['val_loss'])\n",
    "plt.title('Loss Curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [LR, RF, AB, MNB,svm,cat, E,rnn[9],cnn[9],lstm,dnn[4],hyd[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(accuracies)):\n",
    "    accuracies[i] = accuracies[i]*100\n",
    "    print(accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Logistic Regression' , 'Random Forest', 'Decision Tree', 'MNB','SVM','CATBOOSTING' ,'Voting Classifier','RNN','CNN','LSTM','DNN','CNN+LSTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.bar(models,accuracies)\n",
    "# plt.xlabel(\"For First Dataset\")\n",
    "# plt.ylabel(\"Accuracy (in %)\")\n",
    "# plt.show()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracies, color='skyblue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.ylim(0, 100)  # Set y-axis limit to ensure proper scale\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy_values = [\n",
    "    85.15151515151516, 85.15151515151516, 71.57575757575756, 83.51515151515152,\n",
    "    63.57575757575758, 82.60606060606061, 83.51515151515152, 59.299999475479126,\n",
    "    48.80000054836273, 80.29999732971191, 50.80000162124634, 48.899999260902405\n",
    "]\n",
    "\n",
    "models = ['Logistic Regression', 'Random Forest', 'Decision Tree', 'MNB', 'SVM', 'CATBOOSTING', 'Voting Classifier', 'RNN', 'CNN', 'LSTM', 'DNN', 'CNN+LSTM']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, accuracy_values, color='skyblue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.ylim(0, 100)  # Set y-axis limit to ensure proper scale\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
